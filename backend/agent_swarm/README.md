# AI Agent Swarm for Data Science

This module implements an AI Agent Swarm for automating the end-to-end data science workflow. The system leverages a multi-agent architecture built using LlamaIndex and powered by Google's Gemini `flash-lite` language model (via Google AI Studio API).

## System Overview

A central **Orchestrator Agent** dynamically manages the workflow, delegating tasks to specialized agents responsible for distinct data science phases:

- **Data Loading Agent**: Ingests data from various sources
- **Exploration Agent**: Performs initial data analysis and profiling
- **Cleaning Agent**: Preprocesses and cleans data
- **Analysis Agent**: Derives deeper insights from data
- **Modeling Agent**: Develops and evaluates predictive models
- **Visualization Agent**: Generates visual representations
- **Code Action Agent**: Securely executes Python code
- **Reporting Agent**: Compiles final results into a report

## Key Features

- **Dynamic workflow execution**: The Orchestrator determines the sequence of operations based on the evolving state of the analysis and user-defined goals.
- **Transparent and reproducible**: All steps, code executions, rationale, and findings are logged chronologically into a shared, executable **Jupyter Notebook**.
- **Secure code execution**: A dedicated **CodeActAgent** provides a secure environment for executing Python code requested by any agent in the swarm.

## Environment

The Environment serves as the central, shared state repository for the swarm. It contains:

- **Goals**: User-defined objectives for the data science project
- **Data**: References to raw data sources
- **Data Overview**: Results from the Exploration Agent
- **Cleaned Data**: References to cleaned data artifacts
- **Analysis Results**: Insights generated by the Analysis Agent
- **Models**: Information about trained models
- **Visualizations**: References to generated plots
- **JupyterLogbook**: Chronological record of the data science process
- **Available Agents**: Metadata about active agents
- **Execution State/Log**: Internal log of the Orchestrator's decisions

## Usage

To use the AI Agent Swarm, you need to:

1. Set up the language model:
   ```python
   from agent_swarm.main import setup_llm
   
   # Set up the language model (requires Google API key)
   setup_llm(api_key="YOUR_GOOGLE_API_KEY")
   ```

2. Create and run the agent swarm:
   ```python
   from agent_swarm.main import run_agent_swarm
   
   # Define goals and data sources
   goals = ["Explore the data", "Identify key insights", "Build a predictive model"]
   data_sources = {"csv_file": "path/to/data.csv"}
   
   # Run the agent swarm
   result = run_agent_swarm(goals, data_sources)
   ```

3. Access the results:
   ```python
   # Access the JupyterLogbook
   notebook_path = result.get("JupyterLogbook")
   
   # Access other results
   analysis_results = result.get("Analysis Results")
   models = result.get("Models")
   visualizations = result.get("Visualizations")
   ```

## API Endpoints

The AI Agent Swarm is integrated into the DataHammer backend API with the following endpoints:

- `POST /agent-swarm/analyze`: Analyze data using the AI Agent Swarm
- `GET /agent-swarm/agents`: List all available agents in the AI Agent Swarm

## Security Considerations

The `CodeActAgent` executes arbitrary code, which is inherently risky. The current implementation uses a basic sandboxing mechanism, but a production deployment should use a more robust approach such as Docker containers or a restricted Python interpreter.

## Dependencies

- LlamaIndex
- Google Gemini API
- nbformat
- Jupyter
- Pandas, NumPy, scikit-learn, etc. for data science operations